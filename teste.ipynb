{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Recebeu do servidor: {\"message\": \"No card\\\\u00e1pio de hamb\\\\u00fargueres do '\n",
      " 'Mr. Hoppy, voc\\\\u00ea pode escolher entre as seguintes '\n",
      " 'op\\\\u00e7\\\\u00f5es:\\\\n\\\\n1. Smash Cheeseburger - P\\\\u00e3o hamb\\\\u00farguer, '\n",
      " 'smash de 70g, maionese e cheddar - $17\\\\n2. Smash Cheeseburger Duplo - '\n",
      " 'P\\\\u00e3o, 2 hamb\\\\u00fargueres smash de 70g, maionese e cheddar - $24\\\\n3. '\n",
      " 'Classic Salad - P\\\\u00e3o hamb\\\\u00farguer, 110g, maionese, r\\\\u00facula, '\n",
      " 'cebola roxa, tomate e queijo mozzarela - $20\\\\n4. Hoppy Melt - P\\\\u00e3o '\n",
      " 'hamb\\\\u00farguer, 110g, maionese, cheddar derretido coberto por cubos de '\n",
      " 'bacon crocante - $23\\\\n5. Barbie Kill - P\\\\u00e3o hamb\\\\u00farguer, 110g, '\n",
      " 'maionese, queijo mozzarela, molho barbecue secreto coberto por cebola crispy '\n",
      " '- $23\\\\n6. Blue Moon - P\\\\u00e3o hamb\\\\u00farguer, 110g, maionese, creme de '\n",
      " 'gorgonzola coberto com cebola crispy - $23\\\\n7. Bacon Paradise - P\\\\u00e3o '\n",
      " 'hamb\\\\u00farguer, 110g, maionese, creme de bacon coberto por cubos de bacon '\n",
      " 'crocante - $23\\\\n8. Crocodilo Dundee - P\\\\u00e3o australiano, '\n",
      " 'hamb\\\\u00farguer, 110g, maionese, queijo mozzarela, creme de queijo com '\n",
      " 'hortel\\\\u00e3 e lascas de parmes\\\\u00e3o crocante - $27\\\\n\\\\nAp\\\\u00f3s '\n",
      " 'escolher, por favor me informe qual \\\\u00e9 a sua escolha e se deseja algo '\n",
      " 'mais para acompanhar.\"}')\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import websockets\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "async def test_websocket():\n",
    "    uri = \"ws://localhost:8000/ws/assistant/?api_key=chave_teste\"\n",
    "    async with websockets.connect(uri, ping_timeout=500) as websocket:\n",
    "        message = {\"message\": \"quais hamburguer eu posso escolher?\"}\n",
    "        await websocket.send(json.dumps(message))\n",
    "        response = await websocket.recv()\n",
    "        pprint(f\"Recebeu do servidor: {response}\")\n",
    "\n",
    "await test_websocket()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidStatusCode",
     "evalue": "server rejected WebSocket connection: HTTP 500",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidStatusCode\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResposta ao remover: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m websocket\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m test_cart_consumer()\n",
      "Cell \u001b[1;32mIn[21], line 7\u001b[0m, in \u001b[0;36mtest_cart_consumer\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_cart_consumer\u001b[39m():\n\u001b[0;32m      6\u001b[0m     uri \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mws://localhost:8001/ws/cart/?token=token_unico\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m websockets\u001b[38;5;241m.\u001b[39mconnect(uri) \u001b[38;5;28;01mas\u001b[39;00m websocket:\n\u001b[0;32m      9\u001b[0m         comida_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[0;32m     11\u001b[0m         add_message \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     12\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madd\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     13\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomida_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: comida_id,\n\u001b[0;32m     14\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantidade\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     15\u001b[0m         }\n",
      "File \u001b[1;32mc:\\apps\\ass_back_end\\venv\\Lib\\site-packages\\websockets\\legacy\\client.py:629\u001b[0m, in \u001b[0;36mConnect.__aenter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__aenter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m WebSocketClientProtocol:\n\u001b[1;32m--> 629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\apps\\ass_back_end\\venv\\Lib\\site-packages\\websockets\\legacy\\client.py:647\u001b[0m, in \u001b[0;36mConnect.__await_impl_timeout__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    645\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__await_impl_timeout__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m WebSocketClientProtocol:\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m asyncio_timeout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopen_timeout):\n\u001b[1;32m--> 647\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__await_impl__()\n",
      "File \u001b[1;32mc:\\apps\\ass_back_end\\venv\\Lib\\site-packages\\websockets\\legacy\\client.py:654\u001b[0m, in \u001b[0;36mConnect.__await_impl__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    652\u001b[0m protocol \u001b[38;5;241m=\u001b[39m cast(WebSocketClientProtocol, _protocol)\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 654\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mhandshake(\n\u001b[0;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wsuri,\n\u001b[0;32m    656\u001b[0m         origin\u001b[38;5;241m=\u001b[39mprotocol\u001b[38;5;241m.\u001b[39morigin,\n\u001b[0;32m    657\u001b[0m         available_extensions\u001b[38;5;241m=\u001b[39mprotocol\u001b[38;5;241m.\u001b[39mavailable_extensions,\n\u001b[0;32m    658\u001b[0m         available_subprotocols\u001b[38;5;241m=\u001b[39mprotocol\u001b[38;5;241m.\u001b[39mavailable_subprotocols,\n\u001b[0;32m    659\u001b[0m         extra_headers\u001b[38;5;241m=\u001b[39mprotocol\u001b[38;5;241m.\u001b[39mextra_headers,\n\u001b[0;32m    660\u001b[0m     )\n\u001b[0;32m    661\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RedirectHandshake \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    662\u001b[0m     protocol\u001b[38;5;241m.\u001b[39mfail_connection()\n",
      "File \u001b[1;32mc:\\apps\\ass_back_end\\venv\\Lib\\site-packages\\websockets\\legacy\\client.py:325\u001b[0m, in \u001b[0;36mWebSocketClientProtocol.handshake\u001b[1;34m(self, wsuri, origin, available_extensions, available_subprotocols, extra_headers)\u001b[0m\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RedirectHandshake(response_headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLocation\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m status_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m101\u001b[39m:\n\u001b[1;32m--> 325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidStatusCode(status_code, response_headers)\n\u001b[0;32m    327\u001b[0m check_response(response_headers, key)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextensions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_extensions(\n\u001b[0;32m    330\u001b[0m     response_headers, available_extensions\n\u001b[0;32m    331\u001b[0m )\n",
      "\u001b[1;31mInvalidStatusCode\u001b[0m: server rejected WebSocket connection: HTTP 500"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import websockets\n",
    "import json\n",
    "\n",
    "async def test_cart_consumer():\n",
    "    uri = \"ws://localhost:8001/ws/cart/?token=token_unico\"\n",
    "    async with websockets.connect(uri) as websocket:\n",
    "\n",
    "        comida_id = 4\n",
    "\n",
    "        add_message = {\n",
    "            \"action\": \"add\",\n",
    "            \"comida_id\": comida_id,\n",
    "            \"quantidade\": 2\n",
    "        }\n",
    "        await websocket.send(json.dumps(add_message))\n",
    "        response = await websocket.recv()\n",
    "        print(f\"Resposta ao adicionar: {response}\")\n",
    "\n",
    "        view_message = {\"action\": \"view\"}\n",
    "        await websocket.send(json.dumps(view_message))\n",
    "        response = await websocket.recv()\n",
    "        print(f\"Itens no carrinho: {response}\")\n",
    "\n",
    "        remove_message = {\n",
    "            \"action\": \"remove\",\n",
    "            \"comida_id\": comida_id\n",
    "        }\n",
    "        \n",
    "        await websocket.send(json.dumps(remove_message))\n",
    "        response = await websocket.recv()\n",
    "        print(f\"Resposta ao remover: {response}\")\n",
    "        await websocket.close()\n",
    "\n",
    "await test_cart_consumer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[ThreadMessage](data=[ThreadMessage(id='msg_evvLFj9zoPa5FSFIuYdGCLhC', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='Olá, quais opções de hambuguer estão disponíveis?'), type='text')], created_at=1707478210, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_OfYEhXrXgavhHB4MEhWZ6GDV')], object='list', first_id='msg_evvLFj9zoPa5FSFIuYdGCLhC', last_id='msg_evvLFj9zoPa5FSFIuYdGCLhC', has_more=False)\n"
     ]
    }
   ],
   "source": [
    "import django\n",
    "import os\n",
    "\n",
    "\n",
    "os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'core.settings')\n",
    "django.setup()\n",
    "\n",
    "from openai import OpenAI\n",
    "from assistant.env import gpt_key\n",
    "import time\n",
    "\n",
    "class GPT:\n",
    "    def __init__(self) -> None:\n",
    "        self.client = OpenAI(api_key=\"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\")\n",
    "        self.assistant_id = 'asst_UrIDUN3nQaQPvD52nm1WNN3y'\n",
    "        \n",
    "    def retrive_assistant(self):\n",
    "        return self.client.beta.assistants.retrieve(self.assistant_id)\n",
    "    \n",
    "    def list_assistants(self):\n",
    "        return self.client.beta.assistants.list(\n",
    "            order='desc',\n",
    "            limit='20'\n",
    "        )\n",
    "        \n",
    "    def _create_thread(self):\n",
    "        return self.client.beta.threads.create()\n",
    "    \n",
    "    def creat_message(self, message: str, thread_id):\n",
    "        return self.client.beta.threads.messages.create(\n",
    "            thread_id=thread_id,\n",
    "            role='user',\n",
    "            content=message\n",
    "        )\n",
    "    \n",
    "    def run_assistant(self, thread_id, assistant_id):\n",
    "        return self.client.beta.threads.runs.create(\n",
    "            thread_id=thread_id,\n",
    "            assistant_id=assistant_id\n",
    "        )\n",
    "        \n",
    "    def check_status_queue(self, thread_id, run_id):\n",
    "        return self.client.beta.threads.runs.retrieve(\n",
    "            thread_id=thread_id,\n",
    "            run_id=run_id\n",
    "        )\n",
    "\n",
    "    def show_response_assistant(self, message_user):\n",
    "        assistant = self.retrive_assistant()\n",
    "        thread = self._create_thread()\n",
    "        message = self.creat_message(message_user, thread.id)\n",
    "        run = self.run_assistant(thread.id, assistant.id)\n",
    "        \n",
    "        messages = gpt.client.beta.threads.messages.list(\n",
    "            thread_id=thread.id\n",
    "        )\n",
    "        \n",
    "        return messages\n",
    "\n",
    "\n",
    "gpt = GPT()\n",
    "\n",
    "teste = gpt.show_response_assistant('Olá, quais opções de hambuguer estão disponíveis?')\n",
    "\n",
    "print(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_progress\n",
      "in_progress\n",
      "completed\n",
      "completed\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=\"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\")\n",
    "assistant_id = 'asst_UrIDUN3nQaQPvD52nm1WNN3y'\n",
    "\n",
    "my_assistant = client.beta.assistants.retrieve(assistant_id)\n",
    "\n",
    "\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"Olá, tem alguma cerveja disponível? reponda apenas com sim ou nao\"\n",
    ")\n",
    "\n",
    "\n",
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=my_assistant.id,\n",
    ")\n",
    "\n",
    "def check_status(thread_id, run_id):\n",
    "    return client.beta.threads.runs.retrieve(\n",
    "        thread_id=thread_id,\n",
    "        run_id=run_id\n",
    "        )\n",
    "\n",
    "status = check_status(thread.id, run.id)\n",
    "\n",
    "while status.status != 'completed':\n",
    "    time.sleep(10)\n",
    "    status = check_status(thread.id, run.id)\n",
    "    print(status.status)\n",
    "    if status.status == 'failed':\n",
    "        print(status)\n",
    "        break\n",
    "\n",
    "print(status.status)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'assistant_id' from 'assistant.env' (c:\\apps\\ass_back_end\\assistant\\env.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01massistant\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m assistant_id, gpt_key\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mOpenAIAssistantClient\u001b[39;00m:\n\u001b[0;32m     10\u001b[0m   \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'assistant_id' from 'assistant.env' (c:\\apps\\ass_back_end\\assistant\\env.py)"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from assistant.env import assistant_id, gpt_key\n",
    "\n",
    "\n",
    "\n",
    "class OpenAIAssistantClient:\n",
    "  def __init__(self):\n",
    "    self.client = OpenAI(api_key=os.getenv('GPT_KEY'))\n",
    "    self.assistant_id = os.getenv('OPENAI_ASSISTANT_ID')\n",
    "\n",
    "  def create_thread_and_run_assistant(self, user_message, timeout=90):\n",
    "    attempt_count = 0\n",
    "\n",
    "    while True:\n",
    "      attempt_count += 1\n",
    "      print(f\"Tentativa {attempt_count}: Enviando mensagem ao assistente.\")\n",
    "      start_time = time.time()\n",
    "\n",
    "      thread = self.client.beta.threads.create()\n",
    "\n",
    "      self.client.beta.threads.messages.create(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=user_message\n",
    "      )\n",
    "\n",
    "      run = self.client.beta.threads.runs.create(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=self.assistant_id,\n",
    "      )\n",
    "\n",
    "      while True:\n",
    "        elapsed_time = time.time() - start_time\n",
    "        if elapsed_time > timeout:\n",
    "          print(f\"Tempo excedido ({elapsed_time:.2f} segundos). Reenviando a mensagem.\")\n",
    "          break  \n",
    "\n",
    "        status = self.check_status(thread.id, run.id)\n",
    "        if status.status == 'completed':\n",
    "          print(\"Execução completada.\")\n",
    "          return self.retrieve_messages(thread.id)\n",
    "        elif status.status == 'failed':\n",
    "          print(\"Falha na execução:\", status)\n",
    "          return None\n",
    "\n",
    "        time.sleep(10)\n",
    "\n",
    "\n",
    "  def check_status(self, thread_id, run_id):\n",
    "    return self.client.beta.threads.runs.retrieve(\n",
    "      thread_id=thread_id,\n",
    "      run_id=run_id\n",
    "    )\n",
    "\n",
    "  def retrieve_messages(self, thread_id):\n",
    "    messages = self.client.beta.threads.messages.list(thread_id=thread_id)\n",
    "    assistant_messages = [msg for msg in messages.data if msg.role == 'assistant']\n",
    "    return assistant_messages[0].content[0].text.value if assistant_messages else None\n",
    "\n",
    "\n",
    "\n",
    "client = OpenAIAssistantClient()\n",
    "user_message = \"Gostaria de um hamburguer com cheddar e bacon, tem algum?\"\n",
    "response = client.create_thread_and_run_assistant(user_message)\n",
    "\n",
    "if response:\n",
    "  print(\"Resposta do Assistente:\", response)\n",
    "else:\n",
    "  print(\"Nenhuma resposta do Assistente.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
